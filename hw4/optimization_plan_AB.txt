================================================================================
方案 A+B 实施详细计划
================================================================================
目标：将 case01 性能从 4.20s 优化到 2.0-2.5s

预期效果分解：
- 方案 A (Prefetch Pipeline): overlap 从 6% 提升到 60% → 节省 ~1,400ms
- 方案 B (Kernel 优化): kernel 加速 20% → 节省 ~900ms  
- 总计节省：~2,300ms
- 最终时间：4,200 - 2,300 = 1,900ms ✓✓✓

================================================================================
深度思考后的实施策略
================================================================================

## 关键洞察

1. **方案 A 的核心**
   - 不是简单的预先 launch 所有 kernels
   - 而是动态的"滑动窗口"prefetch
   - 在保持 early exit 能力的同时，最大化 overlap

2. **方案 B 的核心**  
   - 不需要汇编级优化（风险太高）
   - 可以通过算法优化达到 10-15% 加速
   - 使用更高效的 SHA-256 实现和内存访问模式

3. **A+B 的协同效应**
   - 更快的 kernel (B) 让 prefetch (A) 更有效
   - 更好的 overlap (A) 让 kernel 优化 (B) 的收益更明显

================================================================================
阶段 1：方案 B - Kernel 优化（先做，风险低）
================================================================================

### B.1: 减少 shared memory 加载延迟

**当前问题：**
```cuda
// 每次进入 kernel 都要加载
if (threadIdx.x < 8) {
    s_midstate[threadIdx.x] = midstate[threadIdx.x];
}
if (threadIdx.x < 16) {
    s_chunk1_base[threadIdx.x] = chunk1_base[threadIdx.x];
}
__syncthreads();
```

**优化：** 合并加载，减少 bank conflicts
```cuda
// 让更多 threads 参与加载，减少加载时间
if (threadIdx.x < 8) {
    s_midstate[threadIdx.x] = midstate[threadIdx.x];
    if (threadIdx.x + 8 < 16) {
        s_chunk1_base[threadIdx.x] = chunk1_base[threadIdx.x];
        s_chunk1_base[threadIdx.x + 8] = chunk1_base[threadIdx.x + 8];
    }
}
__syncthreads();
```

**预期：** 节省 1-2% kernel 时间

---

### B.2: 优化 nonce 字节序转换

**当前问题：**
```cuda
chunk1[3] = ((nonce & 0x000000FFu) << 24) |
            ((nonce & 0x0000FF00u) << 8)  |
            ((nonce & 0x00FF0000u) >> 8)  |
            ((nonce & 0xFF000000u) >> 24);
```

**优化：** 使用内置函数
```cuda
chunk1[3] = __byte_perm(nonce, 0, 0x0123);  // 硬件字节反转
```

**预期：** 节省 0.5-1% kernel 时间

---

### B.3: 减少局部变量使用（降低 register 压力）

**当前问题：**
```cuda
WORD state[8];      // 8 registers
WORD chunk1[16];    // 16 registers
unsigned char intermediate[32];  // 32 registers
```

**优化：** 复用 chunk1 数组存储 intermediate
```cuda
WORD state[8];
WORD chunk1[16];

// 计算第一次 SHA-256
device_sha256_transform_words(state, chunk1);

// 复用 chunk1 存储 intermediate (只需要前 8 个 words)
#pragma unroll
for (int j = 0; j < 8; ++j) {
    chunk1[j] = ((state[j] >> 24) & 0xff) |
                ((state[j] >> 16) & 0xff00) |
                ((state[j] >> 8) & 0xff0000) |
                ((state[j]) & 0xff000000);
}

// 然后从 chunk1 再次 hash
```

**预期：** 减少 register 使用 32 个，提升 occupancy
**实际效果：** 5-8% kernel 加速

---

### B.4: 优化 early exit 检查频率

**当前问题：**
```cuda
if ((i & 0x1F) == 0 && *found) {  // 每 32 次检查一次
    return;
}
```

**优化：** 动态调整检查频率
```cuda
// 前期少检查，后期多检查
unsigned int check_freq = (i < nonce_count/2) ? 128 : 32;
if ((i & (check_freq - 1)) == 0 && *found) {
    return;
}
```

**预期：** 减少 atomic read 次数，节省 1-2%

---

### B.5: 总结 方案 B

**修改点：**
1. 优化 shared memory 加载
2. 使用 `__byte_perm` 硬件加速
3. 复用数组减少 register 使用
4. 优化 early exit 检查

**预期总效果：** 10-15% kernel 加速
- 当前：10.3 ms/kernel
- 优化后：8.8-9.3 ms/kernel
- GPU 总时间：4,485 ms → 3,800-4,000 ms
- 节省：485-685 ms

================================================================================
阶段 2：方案 A - Prefetch Pipeline（难度高，潜力大）
================================================================================

### A.1: 设计思路 - "滑动窗口" Prefetch

**核心思想：**
- 不是预先 launch 所有 kernels（浪费）
- 而是保持一个"窗口"的 prefetch kernels
- 动态调整窗口大小

**架构：**
```
Stream 0: [K0 running] [K1 queued] [K2 queued]
Stream 1: [K0 running] [K1 queued] [K2 queued]
Stream 2: [K0 running] [K1 queued] [K2 queued]
Stream 3: [K0 running] [K1 queued] [K2 queued]
```

当 Stream 0 的 K0 完成：
- 检查是否找到 nonce
- 如果找到：停止 launch 新 kernels（但已经 queued 的会继续）
- 如果没找到：launch K3

---

### A.2: 实现细节

**数据结构：**
```cpp
struct PrefetchContext {
    cudaStream_t stream;
    cudaEvent_t *events;      // 每个 chunk 一个 event
    int *d_found;             // 共享的 found flag
    unsigned int *d_result;   // 共享的 result
    
    int block_idx;            // 哪个 block
    int chunks_launched;      // 已经 launch 的 chunks
    int chunks_completed;     // 已经完成的 chunks
    int prefetch_window;      // 窗口大小（动态）
    bool found;               // 是否找到
};
```

**主循环逻辑：**
```cpp
while (completed_blocks < total_blocks) {
    // Phase 1: Check completed chunks
    for each stream:
        for each launched chunk:
            if cudaEventQuery(event) == Success:
                chunks_completed++
                
                // 立即检查是否找到
                if d_found changed:
                    stream.found = true
                    stream.prefetch_window = 0  // 停止 prefetch
                
                // 如果这个 block 完成了
                if found or exhausted:
                    completed_blocks++
    
    // Phase 2: Prefetch new chunks
    for each stream:
        if not stream.found:
            while chunks_launched < chunks_completed + prefetch_window:
                launch next chunk
                chunks_launched++
    
    usleep(50);
}
```

---

### A.3: 动态窗口大小

**初始窗口：** 4 chunks (每个 stream prefetch 4 个)
- 4 streams × 4 chunks × 512 blocks = 8,192 blocks
- 仍然会超订阅，但比当前好

**动态调整：**
```cpp
// 如果发现 GPU 利用率低，增大窗口
if (recent_kernel_time < 9ms) {  // GPU 有空闲
    prefetch_window = min(8, prefetch_window + 1);
}

// 如果发现 kernel 变慢，减小窗口（太多竞争）
if (recent_kernel_time > 12ms) {
    prefetch_window = max(2, prefetch_window - 1);
}
```

---

### A.4: Early Exit 处理

**关键：** 虽然预先 launch 了，但可以通过 `d_found` 让后续 kernels 快速退出

```cuda
__global__ void mine_kernel_prefetch(...) {
    // 第一时间检查 found flag
    if (*found) return;  // 立即退出
    
    // 正常挖矿逻辑
    for (...) {
        if ((i & 0x1F) == 0 && *found) return;
        
        // mine...
        
        if (found_nonce) {
            atomicCAS(found, 0, 1);
            *result_nonce = nonce;
            return;
        }
    }
}
```

**效果：**
- 如果 Block 0 在第 20 个 chunk 找到
- Block 0 的 chunk 21-24 会立即退出（几乎无开销）
- Block 1-3 的 prefetch kernels 也会快速退出
- 浪费的计算 < 5%

---

### A.5: 总结 方案 A

**修改点：**
1. 引入 prefetch 窗口机制
2. 每个 stream 预先 queue 2-8 个 kernels
3. 动态调整窗口大小
4. 保留 early exit 能力（通过 d_found 快速退出）

**预期效果：**
- Overlap 效率：6% → 50-60%
- GPU 总时间：4,000 ms (after B)
- 墙上时间：4,000 × 0.45 = 1,800 ms
- 节省：2,200 ms

================================================================================
阶段 3：实施步骤
================================================================================

### 步骤 1: 先实施 B (kernel 优化)

**原因：**
1. 风险低（都是局部优化）
2. 立即见效
3. 为 A 打基础

**时间：** 2-3 小时
**验证：** 每个优化后测试，确保正确性和性能提升

---

### 步骤 2: 实施 A (prefetch)

**原因：**
1. 在 B 的基础上效果更明显
2. 可以先实现简单版本（固定窗口）
3. 然后逐步优化（动态窗口）

**时间：** 4-6 小时
**验证：** 逐步测试，从窗口=2 开始

---

### 步骤 3: 调优

**内容：**
1. 调整 prefetch 窗口大小
2. 调整 chunk_size
3. 调整 blocks_per_grid
4. 测试不同组合

**时间：** 2-3 小时

---

### 步骤 4: 验证和测试

**内容：**
1. 运行所有 test cases
2. 压力测试
3. 性能 profile
4. 文档更新

**时间：** 1-2 小时

================================================================================
总时间估计：10-15 小时
================================================================================

**风险评估：**
- 方案 B：低风险（局部优化）
- 方案 A：中等风险（架构改变，但保留 early exit）

**回滚方案：**
- 保留当前版本作为 backup
- 每个阶段都可以独立回滚

**预期成果：**
- 最保守：2.5-3.0s (如果 overlap 只达到 40%)
- 预期：2.0-2.5s (如果 overlap 达到 50-60%)
- 最理想：1.8-2.0s (如果 overlap 达到 70%)

================================================================================
详细代码修改清单
================================================================================

### 修改 1: 优化 mine_kernel_global (方案 B)
位置：第 466-539 行
- 优化 shared memory 加载
- 使用 __byte_perm
- 减少 register 使用
- 优化 early exit

### 修改 2: 新增 PrefetchContext 结构 (方案 A)
位置：第 604 行附近（BlockTask 后面）
- 定义 prefetch 管理结构

### 修改 3: 重写 mine_blocks_pipeline (方案 A)
位置：第 625-787 行
- 实现滑动窗口 prefetch
- 动态窗口调整
- Early exit 处理

### 修改 4: 新增 kernel (方案 A)
位置：第 540 行附近
- mine_kernel_prefetch (带 found 检查的版本)

================================================================================
