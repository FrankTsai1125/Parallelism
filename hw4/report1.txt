GPU Miner Stage B Optimization Plan (2025-11-13)
===============================================

背景
----
最新一次 `perf_summary_20251113_203949.txt` 顯示 `case00` 壁鐘 16.05s、`case01` 9.32s，`nsys` 報告中 GPU 計算仍僅約 1.8s / 4.7s，但 90% 以上的 CUDA API 時間耗在 `cudaEventSynchronize`，host 端也大量停留於 `sem_wait/poll`。原因是 Stage B pipeline 依然一次把整個 GPU 卡在單一 kernel，且遇到沒有即時完成的情況就直接同步等待，導致多 stream scheduling 沒有帶來任何重疊。

優化方向
--------
1. 調整 kernel 規模與 stream 數量  
   - 目前 `blocks_per_grid = 2048` 幾乎吃滿整張卡，導致同時啟動多個 stream 也無法重疊。  
   - 建議先把每個 kernel 的 blocks 降到 512 或 768，再把 `MAX_PIPELINE_STREAMS` 提高到 4~6，並使用 `cudaOccupancyMaxActiveBlocksPerMultiprocessor` 檢查單個 kernel 仍能維持高 occupancy。  
   - 目的：保留適度的空間讓多個 kernel 共存，實現真正的 GPU 併行。

2. 改寫 nonce chunk 切分策略  
   - 現在初始 chunk 約 4M nonces，單次 kernel 就跑 20ms 以上，stream 遭長時間壟斷。  
   - 將 `base_chunk` 降為 `stride / pipeline_streams`（或固定 1M nonces），優先確保所有 block 都能在多個 stream 間快速輪轉。  
   - 只在所有 context 都空閒時才把 chunk 翻倍，上限可保持 8 倍，避免某個 block 長期佔用 GPU。

3. 改善 host 等待策略  
   - 現行主迴圈只要偵測到 `progress == false` 就立即 `cudaEventSynchronize` 第一個 busy context，等同序列化。  
   - 建議改為：  
     a. 每輪全掃一遍 `cudaEventQuery`，先收割已完成的 context；  
     b. 若仍無進度，採用「短暫 sleep/backoff」或挑選最早啟動的 context 等待；  
     c. 增加連續無進度的計數門檻，避免頻繁同步。  
   - 目標：只有在整個 GPU 真正閒置時才阻塞，確保多 stream pipeline 發揮效果。

4. 強化工作輪換公平性  
   - 改善 `ready_queue`：改以等待時間或剩餘 nonce 最少的 block 為優先，避免某個困難 block 重複佔用 stream。  
   - 配合較小 chunk，可以大幅縮短 `case01` 中 `sem_timedwait` 的 4 秒阻塞，提升整體吞吐。

5. 進一步方向  
   - Persistent kernel：以 device-side work queue 取代 host pipeline，減少 kernel 啟動與同步，最終可再把 `case01` 壁鐘壓低。  
   - Multi-nonce 內圈增強：在 host 端預算 message schedule 差值、或提高 `NONCES_PER_THREAD`，趁 GPU 端空間釋放後進一步降低每 nonce 成本。

驗證流程
--------
1. 依序套用 1~4 項優化，每一步都 `make` → `./run_all.sh` → `./run_performance.sh`。  
2. 比較 `time` 報告與 `nsys` 中 `cudaEventSynchronize` 所占比例，確認 host wait 時間下降。  
3. 若 Stage B 達標（`case00` 約 5~6s、`case01` < 7s），再視需求評估 Persistent kernel 與更深入的 GPU 核心微調。

執行計畫
--------
1. Baseline  
   - 重新跑 `./run_all.sh`、`./run_performance.sh` 紀錄基準。  
   - 保持 git 乾淨以利逐步比較。

2. Step 1：Kernel Footprint  
   - 檢視 `mine_bitcoin_kernel` launch，將 `blocks_per_grid` 參數化。  
   - 透過 `cudaOccupancyMaxActiveBlocksPerMultiprocessor` 估算 512~768 blocks 仍能滿足 occupancy。  
   - 將 `MAX_PIPELINE_STREAMS` 提升至 4~6，確保多 kernel 共存。  
   - 以 `#ifdef PROFILE_OCCUPANCY` 避免正式版輸出。

3. Step 2：Chunk 切分策略  
   - 初始 chunk 設為 `stride / active_streams`（約 1M nonces），確保輪轉頻繁。  
   - 僅於所有 context 閒置時才將 chunk 倍增，上限維持 8 倍。  
   - 以 `align_to_stride` 修正不足 stride 的情況。

4. Step 3：Host 非阻塞迴圈  
   - 主迴圈先全數 `cudaEventQuery` 收割完成 context。  
   - 若數輪皆無進度，才對最早的 busy context `cudaEventSynchronize`，並加入短暫 sleep/backoff。  
   - 加上 `DEBUG_PIPELINE` 計數器取代 `printf`。

5. Step 4：調整排程公平性  
   - 將 `ready_queue` 改成依待機時間或剩餘 nonce 排序。  
   - 完成後僅在 `!completed` 時重入佇列並清除 `inflight`。  
   - 確保 nonce 區間耗盡時不再排程。

6. Step 5：儀表與紀錄  
   - 以 `std::chrono` 在 debug 模式記錄 kernel launch/completion 時間。  
   - 建立 `perf_notes.md`（或報告附錄）記錄每次調整前後指標。

7. Step 6：逐步驗證  
   - 每完成一大步即重建並跑 `./run_all.sh`、必要時跑 `./run_case.sh 00/01`。  
   - 若失敗即回滾最近變更，保持 pipeline 穩定。  
   - 待所有步驟通過後再做最終 profiling。

8. Step 7：最終量測  
   - 以 `nsys profile ./run_case.sh 00` / `01` 確認 `cudaEventSynchronize` 比例下降。  
   - 若仍未達標，再評估 Persistent kernel 或調整 `NONCES_PER_THREAD`。


